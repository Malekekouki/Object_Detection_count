{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24554cc1",
   "metadata": {},
   "source": [
    "  # - Object Detection and Counting -"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee2f2e1",
   "metadata": {},
   "source": [
    "                                                 Realized by : Maleke KOUKI       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1087d7a",
   "metadata": {},
   "source": [
    "    This file displays the testing of object detection and counting on images, videos and our camera lens, which is our primary object. \n",
    "    \n",
    "    During this project, we decided to employ the SSD method, which is based on the combination of YOLO for its accuracy and R-CNN for its velocity. For performance considerations, we'll use MobileNetV2. \n",
    "    SSD (Single Shot MultiBox Detector) is an object detection architecture based on a CNN architecture, while MobileNetV2 is a CNN architecture optimized for feature extraction. They are often used together in object detection models to take advantage of MobileNetV2's efficiency and SSD's object detection capabilities, creating a balanced and efficient object detection system.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50bf134d",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c04c4c",
   "metadata": {},
   "source": [
    "- Capturer des flux vidéo depuis la caméra et l'affichage du résultat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3a1cc2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\malek\\anaconda3\\lib\\site-packages (4.7.0.72)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\malek\\anaconda3\\lib\\site-packages (from opencv-python) (1.24.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86e12614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenCV version: 4.7.0\n",
      "OpenCV is properly installed.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# Get OpenCV version\n",
    "print(\"OpenCV version:\", cv2.__version__)\n",
    "\n",
    "# Check if OpenCV is available\n",
    "if cv2:\n",
    "    print(\"OpenCV is properly installed.\")\n",
    "else:\n",
    "    print(\"OpenCV is not installed or not properly configured.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42141575",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7cc65c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = 'img.jpg'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf24ab7c",
   "metadata": {},
   "source": [
    "- The prototxt file : defines the architecture of the model ( the different layers, the output, input, pooling...).\n",
    "- The caffemodel file :  contains the actual numerical values (weights: The parameters that are learned during the training process) associated with each connection in the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d4ca998",
   "metadata": {},
   "outputs": [],
   "source": [
    "prototxt_path = 'C:/Users/malek/Desktop/stage2023/object detection/models/MobileNetSSD_deploy.prototxt'\n",
    "model_path = 'C:/Users/malek/Desktop/stage2023/object detection/models/MobileNetSSD_deploy.caffemodel'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0f32cb",
   "metadata": {},
   "source": [
    "- Define the minimum confidence of the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4789e0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_confidence = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498bd1a6",
   "metadata": {},
   "source": [
    "- Define the list of different objects "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7e017964",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = ('background',\n",
    "           'aeroplane', 'bicycle', 'bird', 'boat',\n",
    "           'bottle', 'bus', 'car', 'cat', 'chair',\n",
    "           'cow', 'diningtable', 'dog', 'truck',\n",
    "           'motorbike', 'person', 'pottedplant',\n",
    "           'sheep', 'sofa', 'train', 'tvmonitor', 'banana')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714e7693",
   "metadata": {},
   "source": [
    "- Define the color of the rectangles of the detected objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5f18b39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(543210) #for color problem solving\n",
    "colors = np.random.uniform(0, 255, size=(len(CLASSES), 3)) #problem: we can have similar colors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85603918",
   "metadata": {},
   "source": [
    "- Load the pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "49b1b56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = cv2.dnn.readNetFromCaffe(prototxt_path, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8b47a6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if net.empty():\n",
    "    print(\"Error loading the model.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a742ce",
   "metadata": {},
   "source": [
    "# 1- Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e187a654",
   "metadata": {},
   "source": [
    "- import the image into the neural network and resize it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "58fdfb31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.         15.          0.94687384  0.50484574  0.3137808   0.6396011\n",
      "  0.5986711 ]\n"
     ]
    }
   ],
   "source": [
    "image = cv2.imread(image_path)\n",
    "height, width = image.shape[0], image.shape[1]\n",
    "blob  = cv2.dnn.blobFromImage(cv2.resize(image, (300, 300)), 0.007, (300,300), 130)\n",
    "#put the image into the neural network\n",
    "net.setInput(blob)\n",
    "detected_objects = net.forward()\n",
    "print(detected_objects[0][0][0]) #result : values of the first object detected "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542ecff2",
   "metadata": {},
   "source": [
    " - 9: the type of the object which is mentionned in the list (object number 9 ) \n",
    " - 0.975 : the confidence \n",
    " - others : are the coordinates x and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7e2c9369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a dictionary to count each class of object\n",
    "object_counts = {class_name: 0 for class_name in CLASSES[1:]}  # Exclude 'background'\n",
    "\n",
    "for i in range(detected_objects.shape[2]):\n",
    "    confidence = detected_objects[0][0][i][2] #to get the confidence\n",
    "    if confidence > min_confidence: #to test if the confidence > min then we draw a rectangle on the object\n",
    "        class_id = int(detected_objects[0, 0, i, 1])\n",
    "        class_name = CLASSES[class_id]\n",
    "        if class_name in object_counts:\n",
    "            object_counts[class_name] += 1\n",
    "    #to get the exact coordinates of the whole object\n",
    "        upper_left_x = int(detected_objects[0, 0, i, 3]* width)\n",
    "        upper_left_y = int(detected_objects[0, 0, i, 4]* height)\n",
    "        lower_right_x = int(detected_objects[0, 0, i, 5]* width)\n",
    "        lower_right_y = int(detected_objects[0, 0, i, 6]* height) \n",
    "    #get the name of the object and the value of the confidence\n",
    "        prediction_txt = f\"{CLASSES[class_id]}: {confidence:.2f}%\"  \n",
    "    #draw the rectangle\n",
    "        cv2.rectangle(image, (upper_left_x, upper_left_y), (lower_right_x, lower_right_y), colors[class_id], 3)\n",
    "    #the position of the text ( if there is no space we change the position)\n",
    "        cv2.putText(image, prediction_txt, (upper_left_x, upper_left_y - 15 if upper_left_y > 30 else upper_left_y + 15), cv2.FONT_HERSHEY_SIMPLEX, 0.6, colors[class_id], 2)\n",
    "                                 \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "96908cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display object counts on the image\n",
    "y_position = 30\n",
    "for class_name, count in object_counts.items():\n",
    "    cv2.putText(image, f\"{class_name}: {count}\", (10, y_position), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    y_position += 30\n",
    "cv2.imshow(\"Detected objects\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce73075",
   "metadata": {},
   "source": [
    "- we use an 'object_counts' dictionary to track the number of occurrences of each object class detected in the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cdd2d904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of detected objects: 20\n",
      "aeroplane: 0 objects\n",
      "bicycle: 0 objects\n",
      "bird: 0 objects\n",
      "boat: 0 objects\n",
      "bottle: 0 objects\n",
      "bus: 0 objects\n",
      "car: 0 objects\n",
      "cat: 0 objects\n",
      "chair: 0 objects\n",
      "cow: 0 objects\n",
      "diningtable: 0 objects\n",
      "dog: 1 objects\n",
      "truck: 0 objects\n",
      "motorbike: 0 objects\n",
      "person: 7 objects\n",
      "pottedplant: 0 objects\n",
      "sheep: 0 objects\n",
      "sofa: 1 objects\n",
      "train: 0 objects\n",
      "tvmonitor: 0 objects\n"
     ]
    }
   ],
   "source": [
    "# count the number of objects detected\n",
    "print(\"Number of detected objects:\", len(object_counts))\n",
    "for class_name, count in object_counts.items():\n",
    "    print(f\"{class_name}: {count} objects\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3228f4db",
   "metadata": {},
   "source": [
    "# 2- video"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d00c6c2",
   "metadata": {},
   "source": [
    "For a video, we have to capture the frames and process each frame individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c14b5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the video path\n",
    "video_path = 'traffic.mp4'  \n",
    "\n",
    "# Open the video file\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Initialize a dictionary to count each class of object\n",
    "object_counts = {class_name: 0 for class_name in CLASSES[1:]}  # Exclude 'background'\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()  # Read a frame from the video\n",
    "\n",
    "    if not ret:\n",
    "        break  # Break the loop if the video has ended\n",
    "\n",
    "    height, width = frame.shape[0], frame.shape[1]\n",
    "    blob = cv2.dnn.blobFromImage(cv2.resize(frame, (300, 300)), 0.007, (300, 300), 130)\n",
    "    net.setInput(blob)\n",
    "    detected_objects = net.forward()\n",
    "\n",
    "    for i in range(detected_objects.shape[2]):\n",
    "        confidence = detected_objects[0][0][i][2]\n",
    "        if confidence > min_confidence:\n",
    "            class_id = int(detected_objects[0, 0, i, 1])\n",
    "            #\n",
    "            class_name = CLASSES[class_id]\n",
    "            if class_name in object_counts:\n",
    "                object_counts[class_name] += 1\n",
    "            upper_left_x = int(detected_objects[0, 0, i, 3] * width)\n",
    "            upper_left_y = int(detected_objects[0, 0, i, 4] * height)\n",
    "            lower_right_x = int(detected_objects[0, 0, i, 5] * width)\n",
    "            lower_right_y = int(detected_objects[0, 0, i, 6] * height)\n",
    "            prediction_txt = f\"{CLASSES[class_id]}: {confidence:.2f}%\"\n",
    "            cv2.rectangle(frame, (upper_left_x, upper_left_y), (lower_right_x, lower_right_y), colors[class_id], 3)\n",
    "            cv2.putText(frame, prediction_txt, (upper_left_x, upper_left_y - 15 if upper_left_y > 30 else upper_left_y + 15),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, colors[class_id], 2)\n",
    "\n",
    "    # Display object counts on the frame\n",
    "    y_position = 30\n",
    "    for class_name, count in object_counts.items():\n",
    "        cv2.putText(frame, f\"{class_name}: {count}\", (10, y_position), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        y_position += 30\n",
    "    \n",
    "    cv2.imshow(\"Detected objects\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):  #q : if we press q the window will be closed\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96f1fd3",
   "metadata": {},
   "source": [
    "# 3- Webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf7c2a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[ 0.         15.          0.5869797   0.0166032   0.3362716   0.96063876\n",
      "  0.99549127]\n",
      "[ 0.         15.          0.98055387  0.03561494  0.40419468  0.9451518\n",
      "  1.0025605 ]\n",
      "[ 0.         15.          0.9798772   0.04478461  0.39916     0.9389892\n",
      "  1.0034566 ]\n",
      "[ 0.         15.          0.98233265  0.02544087  0.37237734  0.97572416\n",
      "  0.99761754]\n",
      "[0.0000000e+00 1.5000000e+01 9.8930675e-01 1.3895363e-02 3.4237641e-01\n",
      " 9.8863828e-01 9.9555796e-01]\n",
      "[ 0.         15.          0.98283494  0.01806551  0.34690216  0.98723704\n",
      "  0.99568653]\n",
      "[ 0.         15.          0.9612344   0.01833183  0.36919916  0.98673004\n",
      "  0.9949087 ]\n",
      "[0.0000000e+00 1.5000000e+01 9.7305793e-01 1.3500184e-02 3.7148130e-01\n",
      " 9.8748672e-01 9.9543846e-01]\n",
      "[ 0.         15.          0.9595606   0.01510254  0.3780044   0.9869721\n",
      "  0.99541783]\n",
      "[0.0000000e+00 1.5000000e+01 9.5758122e-01 2.8273463e-03 3.8291740e-01\n",
      " 9.9213278e-01 9.9930549e-01]\n",
      "[0.0000000e+00 1.5000000e+01 9.5323616e-01 1.4133155e-03 3.8105339e-01\n",
      " 9.8841393e-01 1.0002227e+00]\n",
      "[ 0.         15.          0.95707965  0.05450827  0.37915447  0.9567135\n",
      "  1.0094867 ]\n",
      "[ 0.         15.          0.9343773   0.04362461  0.3764906   0.9598986\n",
      "  1.0096622 ]\n",
      "[0.0000000e+00 1.5000000e+01 9.5858556e-01 1.1339158e-02 3.7437269e-01\n",
      " 9.8063862e-01 9.9543357e-01]\n",
      "[0.0000000e+00 1.5000000e+01 9.8187226e-01 1.3013631e-02 3.5619086e-01\n",
      " 9.8887241e-01 9.9557978e-01]\n",
      "[0.0000000e+00 1.5000000e+01 9.5031542e-01 4.8311949e-03 3.7444845e-01\n",
      " 9.8449379e-01 9.9689984e-01]\n",
      "[0.0000000e+00 1.5000000e+01 9.5031542e-01 4.8311949e-03 3.7444845e-01\n",
      " 9.8449379e-01 9.9689984e-01]\n",
      "[ 0.         15.          0.97907984  0.01734644  0.37068623  0.98430187\n",
      "  0.9958554 ]\n",
      "[0.0000000e+00 1.5000000e+01 9.5259804e-01 8.9883804e-05 3.7611607e-01\n",
      " 9.8111492e-01 1.0008610e+00]\n",
      "[0.0000000e+00 1.5000000e+01 9.5259804e-01 8.9883804e-05 3.7611607e-01\n",
      " 9.8111492e-01 1.0008610e+00]\n",
      "[0.0000000e+00 1.5000000e+01 9.5434570e-01 5.7540834e-03 3.7249908e-01\n",
      " 9.8225093e-01 9.9712515e-01]\n",
      "[0.0000000e+00 1.5000000e+01 9.5553344e-01 4.0251315e-03 3.7539667e-01\n",
      " 9.8215067e-01 9.9710304e-01]\n",
      "[0.0000000e+00 1.5000000e+01 9.5553344e-01 4.0251315e-03 3.7539667e-01\n",
      " 9.8215067e-01 9.9710304e-01]\n",
      "[ 0.         15.          0.9783691   0.01647955  0.36860698  0.98522407\n",
      "  0.9948401 ]\n",
      "[0.0000000e+00 1.5000000e+01 9.5269984e-01 9.6140504e-03 3.7237960e-01\n",
      " 9.7892749e-01 9.9844307e-01]\n",
      "[0.0000000e+00 1.5000000e+01 9.5811039e-01 4.6274960e-03 3.6551362e-01\n",
      " 9.8186636e-01 9.9791259e-01]\n",
      "[0.0000000e+00 1.5000000e+01 9.5811039e-01 4.6274960e-03 3.6551362e-01\n",
      " 9.8186636e-01 9.9791259e-01]\n",
      "[ 0.0000000e+00  1.5000000e+01  9.5266104e-01 -1.2436211e-03\n",
      "  3.7271345e-01  9.8230231e-01  1.0010668e+00]\n",
      "[ 0.0000000e+00  1.5000000e+01  9.5266104e-01 -1.2436211e-03\n",
      "  3.7271345e-01  9.8230231e-01  1.0010668e+00]\n",
      "[ 0.         15.          0.9481806   0.01550221  0.3640122   0.9859214\n",
      "  0.9947481 ]\n",
      "[0.0000000e+00 1.5000000e+01 9.5993030e-01 1.0373622e-02 3.4646246e-01\n",
      " 9.9160671e-01 9.9512434e-01]\n",
      "[0.0000000e+00 1.5000000e+01 9.5993030e-01 1.0373622e-02 3.4646246e-01\n",
      " 9.9160671e-01 9.9512434e-01]\n",
      "[0.0000000e+00 1.5000000e+01 9.8949045e-01 1.1496574e-02 3.4308803e-01\n",
      " 9.8896956e-01 9.9580204e-01]\n",
      "[0.0000000e+00 1.5000000e+01 9.8215497e-01 1.2197077e-02 3.3492747e-01\n",
      " 9.8838538e-01 9.9412084e-01]\n",
      "[0.0000000e+00 1.5000000e+01 9.8215497e-01 1.2197077e-02 3.3492747e-01\n",
      " 9.8838538e-01 9.9412084e-01]\n",
      "[0.0000000e+00 1.5000000e+01 9.8445779e-01 7.6883137e-03 3.0690360e-01\n",
      " 9.9265134e-01 9.9434257e-01]\n",
      "[0.0000000e+00 1.5000000e+01 9.8257488e-01 1.2252182e-02 3.1970990e-01\n",
      " 9.8885512e-01 9.9537003e-01]\n",
      "[0.0000000e+00 1.5000000e+01 9.8257488e-01 1.2252182e-02 3.1970990e-01\n",
      " 9.8885512e-01 9.9537003e-01]\n",
      "[ 0.         15.          0.97953886  0.01789299  0.34299392  0.9835789\n",
      "  0.99410254]\n",
      "[0.0000000e+00 1.5000000e+01 9.5423484e-01 1.2837023e-02 3.1826076e-01\n",
      " 9.8779798e-01 9.9364889e-01]\n",
      "[0.0000000e+00 1.5000000e+01 9.5423484e-01 1.2837023e-02 3.1826076e-01\n",
      " 9.8779798e-01 9.9364889e-01]\n",
      "[ 0.         15.          0.984421    0.015441    0.3334061   0.98524827\n",
      "  0.99452233]\n",
      "[0.0000000e+00 1.5000000e+01 9.7178572e-01 1.1780024e-02 3.1928527e-01\n",
      " 9.8898935e-01 9.9406826e-01]\n",
      "[0.0000000e+00 1.5000000e+01 9.7178572e-01 1.1780024e-02 3.1928527e-01\n",
      " 9.8898935e-01 9.9406826e-01]\n",
      "[0.0000000e+00 1.5000000e+01 9.3018115e-01 1.2109935e-02 3.2017556e-01\n",
      " 9.8925132e-01 9.9315989e-01]\n",
      "[ 0.         15.          0.9831117   0.01642293  0.32808718  0.985105\n",
      "  0.9940034 ]\n",
      "[ 0.         15.          0.9831117   0.01642293  0.32808718  0.985105\n",
      "  0.9940034 ]\n",
      "[0.0000000e+00 1.5000000e+01 9.7878224e-01 1.1987537e-02 3.1303570e-01\n",
      " 9.8929811e-01 9.9429858e-01]\n",
      "[0.0000000e+00 1.5000000e+01 9.7878224e-01 1.1987537e-02 3.1303570e-01\n",
      " 9.8929811e-01 9.9429858e-01]\n",
      "[ 0.         15.          0.97096753  0.01525685  0.3226429   0.9859164\n",
      "  0.9939543 ]\n",
      "[ 0.         15.          0.9617258   0.01611698  0.3300053   0.98529184\n",
      "  0.99298954]\n",
      "[ 0.         15.          0.9617258   0.01611698  0.3300053   0.98529184\n",
      "  0.99298954]\n",
      "[ 0.         15.          0.9851164   0.01735538  0.33773145  0.98346657\n",
      "  0.99434066]\n",
      "[0.0000000e+00 1.5000000e+01 9.8416060e-01 1.4274031e-02 3.2357034e-01\n",
      " 9.8681378e-01 9.9432385e-01]\n",
      "[0.0000000e+00 1.5000000e+01 9.8416060e-01 1.4274031e-02 3.2357034e-01\n",
      " 9.8681378e-01 9.9432385e-01]\n",
      "[ 0.         15.          0.98703617  0.01767755  0.33276415  0.9841149\n",
      "  0.99479747]\n",
      "[0.0000000e+00 1.5000000e+01 9.7586960e-01 9.1976225e-03 3.0351996e-01\n",
      " 9.9188888e-01 9.9453902e-01]\n",
      "[0.0000000e+00 1.5000000e+01 9.7586960e-01 9.1976225e-03 3.0351996e-01\n",
      " 9.9188888e-01 9.9453902e-01]\n",
      "[ 0.         15.          0.96906865  0.0162361   0.32308763  0.9849646\n",
      "  0.99352604]\n",
      "[ 0.         15.          0.9848696   0.01506275  0.32573658  0.9861409\n",
      "  0.99391097]\n",
      "[ 0.         15.          0.9848696   0.01506275  0.32573658  0.9861409\n",
      "  0.99391097]\n",
      "[0.0000000e+00 1.5000000e+01 9.7351509e-01 1.2731165e-02 3.1346086e-01\n",
      " 9.8786926e-01 9.9426401e-01]\n",
      "[0.0000000e+00 1.5000000e+01 9.8895895e-01 1.0798842e-02 3.1028330e-01\n",
      " 9.8952162e-01 9.9496830e-01]\n",
      "[0.0000000e+00 1.5000000e+01 9.8895895e-01 1.0798842e-02 3.1028330e-01\n",
      " 9.8952162e-01 9.9496830e-01]\n",
      "[ 0.         15.          0.9847109   0.01617813  0.33027107  0.9850483\n",
      "  0.9939365 ]\n",
      "[ 0.         15.          0.9931705   0.01690504  0.32784793  0.98384416\n",
      "  0.9955703 ]\n",
      "[ 0.         15.          0.9931705   0.01690504  0.32784793  0.98384416\n",
      "  0.9955703 ]\n",
      "[ 0.         15.          0.9893127   0.01759589  0.3312277   0.983166\n",
      "  0.99426365]\n",
      "[ 0.         15.          0.98409885  0.01577058  0.3210984   0.9850919\n",
      "  0.9950264 ]\n",
      "[ 0.         15.          0.98409885  0.01577058  0.3210984   0.9850919\n",
      "  0.9950264 ]\n",
      "[ 0.         15.          0.97938615  0.0160813   0.3262034   0.985181\n",
      "  0.9938243 ]\n",
      "[ 0.         15.          0.98579013  0.01592258  0.32216868  0.9848573\n",
      "  0.99394405]\n",
      "[ 0.         15.          0.98579013  0.01592258  0.32216868  0.9848573\n",
      "  0.99394405]\n",
      "[ 0.         15.          0.9882923   0.01534653  0.3300357   0.9849342\n",
      "  0.9943483 ]\n",
      "[ 0.         15.          0.99098295  0.01510879  0.32115525  0.9852145\n",
      "  0.99471384]\n",
      "[ 0.         15.          0.99098295  0.01510879  0.32115525  0.9852145\n",
      "  0.99471384]\n",
      "[ 0.         15.          0.97285134  0.0150418   0.3276417   0.98559797\n",
      "  0.99384415]\n",
      "[0.0000000e+00 1.5000000e+01 9.8708922e-01 1.4575690e-02 3.2343572e-01\n",
      " 9.8664021e-01 9.9380881e-01]\n",
      "[0.0000000e+00 1.5000000e+01 9.8916781e-01 1.4774948e-02 3.1856394e-01\n",
      " 9.8650169e-01 9.9461830e-01]\n",
      "[ 0.         15.          0.9880163   0.01611996  0.3281145   0.9847405\n",
      "  0.9940349 ]\n",
      "[ 0.         15.          0.9880163   0.01611996  0.3281145   0.9847405\n",
      "  0.9940349 ]\n",
      "[0.00000000e+00 1.50000000e+01 9.83655453e-01 1.21870935e-02\n",
      " 3.05515945e-01 9.88256454e-01 9.94576275e-01]\n",
      "[0.00000000e+00 1.50000000e+01 9.84510124e-01 1.49027705e-02\n",
      " 3.18368256e-01 9.86316383e-01 9.94325936e-01]\n",
      "[0.00000000e+00 1.50000000e+01 9.84510124e-01 1.49027705e-02\n",
      " 3.18368256e-01 9.86316383e-01 9.94325936e-01]\n",
      "[0.0000000e+00 1.5000000e+01 9.6096605e-01 1.3390303e-02 3.0791792e-01\n",
      " 9.8751009e-01 9.9478841e-01]\n",
      "[0.0000000e+00 1.5000000e+01 9.4137949e-01 1.3874263e-02 3.0732852e-01\n",
      " 9.8745823e-01 9.9329358e-01]\n",
      "[0.0000000e+00 1.5000000e+01 9.4137949e-01 1.3874263e-02 3.0732852e-01\n",
      " 9.8745823e-01 9.9329358e-01]\n",
      "[0.0000000e+00 1.5000000e+01 9.8110974e-01 8.9419484e-03 3.0053526e-01\n",
      " 9.9152952e-01 9.9403626e-01]\n",
      "[0.0000000e+00 1.5000000e+01 9.4631380e-01 7.3993504e-03 3.0000484e-01\n",
      " 9.9434447e-01 9.9344289e-01]\n",
      "[0.0000000e+00 1.5000000e+01 9.4631380e-01 7.3993504e-03 3.0000484e-01\n",
      " 9.9434447e-01 9.9344289e-01]\n",
      "[0.0000000e+00 1.5000000e+01 8.8800353e-01 6.4138770e-03 2.9799393e-01\n",
      " 9.9412268e-01 9.9389875e-01]\n",
      "[0.0000000e+00 1.5000000e+01 9.4158995e-01 3.2668710e-03 2.7011430e-01\n",
      " 9.9568468e-01 9.9681711e-01]\n",
      "[0.0000000e+00 1.5000000e+01 9.4158995e-01 3.2668710e-03 2.7011430e-01\n",
      " 9.9568468e-01 9.9681711e-01]\n",
      "[0.0000000e+00 1.5000000e+01 8.9945394e-01 7.4898303e-03 3.2847947e-01\n",
      " 9.9446344e-01 9.9319237e-01]\n",
      "[0.0000000e+00 1.5000000e+01 7.9900867e-01 5.4309964e-03 3.1782472e-01\n",
      " 9.9453920e-01 9.9303246e-01]\n",
      "[0.0000000e+00 1.5000000e+01 7.9900867e-01 5.4309964e-03 3.1782472e-01\n",
      " 9.9453920e-01 9.9303246e-01]\n",
      "[ 0.         15.          0.9558003   0.01831761  0.36480796  0.982898\n",
      "  0.99394286]\n",
      "[0.0000000e+00 1.5000000e+01 9.7868186e-01 9.9125803e-03 3.7955570e-01\n",
      " 9.7466683e-01 9.9858010e-01]\n",
      "[0.0000000e+00 1.5000000e+01 9.7868186e-01 9.9125803e-03 3.7955570e-01\n",
      " 9.7466683e-01 9.9858010e-01]\n",
      "[ 0.0000000e+00  1.5000000e+01  9.7984457e-01 -8.4131956e-05\n",
      "  3.7897098e-01  9.8323178e-01  9.9951530e-01]\n",
      "[ 0.0000000e+00  1.5000000e+01  9.7984457e-01 -8.4131956e-05\n",
      "  3.7897098e-01  9.8323178e-01  9.9951530e-01]\n",
      "[0.0000000e+00 1.5000000e+01 9.4884640e-01 7.6649785e-03 3.6035028e-01\n",
      " 9.8291558e-01 9.9990475e-01]\n",
      "[ 0.         15.          0.9493491   0.0177801   0.36197686  0.9819778\n",
      "  0.99849665]\n",
      "[ 0.         15.          0.9493491   0.0177801   0.36197686  0.9819778\n",
      "  0.99849665]\n",
      "[0.0000000e+00 1.5000000e+01 9.6209949e-01 1.0398477e-02 3.7069905e-01\n",
      " 9.8194444e-01 9.9735987e-01]\n",
      "[0.0000000e+00 1.5000000e+01 9.7423899e-01 1.4281064e-02 3.6811143e-01\n",
      " 9.8695385e-01 9.9590188e-01]\n",
      "[0.0000000e+00 1.5000000e+01 9.7423899e-01 1.4281064e-02 3.6811143e-01\n",
      " 9.8695385e-01 9.9590188e-01]\n",
      "[0.0000000e+00 1.5000000e+01 9.5717806e-01 1.4099985e-02 3.6845359e-01\n",
      " 9.8374557e-01 9.9817872e-01]\n",
      "[0.0000000e+00 1.5000000e+01 9.5753151e-01 9.5104575e-03 3.6705095e-01\n",
      " 9.8262870e-01 9.9799830e-01]\n",
      "[0.0000000e+00 1.5000000e+01 9.5753151e-01 9.5104575e-03 3.6705095e-01\n",
      " 9.8262870e-01 9.9799830e-01]\n",
      "[0.0000000e+00 1.5000000e+01 9.5492995e-01 1.2009859e-02 3.6318526e-01\n",
      " 9.8295599e-01 9.9961758e-01]\n",
      "[ 0.         15.          0.95994574  0.01606804  0.36578527  0.97923374\n",
      "  0.99736536]\n",
      "[ 0.         15.          0.95994574  0.01606804  0.36578527  0.97923374\n",
      "  0.99736536]\n",
      "[ 0.         15.          0.95854664  0.01553005  0.36264494  0.98060346\n",
      "  0.9977319 ]\n",
      "[0.0000000e+00 1.5000000e+01 9.6607357e-01 8.6672902e-03 3.6428139e-01\n",
      " 9.8103315e-01 1.0002096e+00]\n",
      "[0.0000000e+00 1.5000000e+01 9.6607357e-01 8.6672902e-03 3.6428139e-01\n",
      " 9.8103315e-01 1.0002096e+00]\n",
      "[0.0000000e+00 1.5000000e+01 9.6418875e-01 1.0972470e-02 3.6942324e-01\n",
      " 9.8289251e-01 9.9774575e-01]\n",
      "[0.0000000e+00 1.5000000e+01 9.6418875e-01 1.0972470e-02 3.6942324e-01\n",
      " 9.8289251e-01 9.9774575e-01]\n",
      "[0.0000000e+00 1.5000000e+01 9.7039121e-01 4.4693649e-03 3.7375194e-01\n",
      " 9.8458958e-01 9.9844950e-01]\n",
      "[0.0000000e+00 1.5000000e+01 9.6467453e-01 5.7509243e-03 3.6808866e-01\n",
      " 9.8417163e-01 9.9971277e-01]\n",
      "[0.0000000e+00 1.5000000e+01 9.6467453e-01 5.7509243e-03 3.6808866e-01\n",
      " 9.8417163e-01 9.9971277e-01]\n",
      "[0.0000000e+00 1.5000000e+01 9.6253300e-01 6.7289174e-03 3.6684355e-01\n",
      " 9.8390591e-01 9.9778676e-01]\n",
      "[0.0000000e+00 1.5000000e+01 9.6253300e-01 6.7289174e-03 3.6684355e-01\n",
      " 9.8390591e-01 9.9778676e-01]\n",
      "[0.00000000e+00 1.50000000e+01 9.58246410e-01 1.31314695e-02\n",
      " 3.62767339e-01 9.83240843e-01 9.99775290e-01]\n",
      "[0.0000000e+00 1.5000000e+01 9.6232665e-01 1.0125220e-02 3.6468950e-01\n",
      " 9.8400044e-01 1.0002400e+00]\n",
      "[0.0000000e+00 1.5000000e+01 9.6232665e-01 1.0125220e-02 3.6468950e-01\n",
      " 9.8400044e-01 1.0002400e+00]\n",
      "[0.0000000e+00 1.5000000e+01 9.5470780e-01 9.8125935e-03 3.6300492e-01\n",
      " 9.8512608e-01 9.9852204e-01]\n",
      "[0.0000000e+00 1.5000000e+01 9.4714719e-01 5.6847036e-03 3.6927083e-01\n",
      " 9.8078585e-01 1.0006945e+00]\n",
      "[0.0000000e+00 1.5000000e+01 9.4714719e-01 5.6847036e-03 3.6927083e-01\n",
      " 9.8078585e-01 1.0006945e+00]\n",
      "[0.0000000e+00 1.5000000e+01 9.5852727e-01 1.4430791e-02 3.6535695e-01\n",
      " 9.8323607e-01 9.9967051e-01]\n",
      "[0.0000000e+00 1.5000000e+01 9.5852727e-01 1.4430791e-02 3.6535695e-01\n",
      " 9.8323607e-01 9.9967051e-01]\n",
      "[ 0.         15.          0.96572477  0.01538911  0.36034834  0.98629606\n",
      "  0.9957434 ]\n",
      "[0.0000000e+00 1.5000000e+01 9.8030806e-01 1.4921576e-02 3.6509427e-01\n",
      " 9.8637342e-01 9.9632835e-01]\n",
      "[0.0000000e+00 1.5000000e+01 9.8030806e-01 1.4921576e-02 3.6509427e-01\n",
      " 9.8637342e-01 9.9632835e-01]\n",
      "[ 0.         15.          0.9471134   0.01624444  0.36690822  0.9848342\n",
      "  0.9944984 ]\n",
      "[0.0000000e+00 1.5000000e+01 9.6133596e-01 1.2193143e-02 3.6604476e-01\n",
      " 9.8108429e-01 1.0002224e+00]\n",
      "[0.0000000e+00 1.5000000e+01 9.5152748e-01 6.9016814e-03 3.6035070e-01\n",
      " 9.8137832e-01 1.0001261e+00]\n",
      "[0.0000000e+00 1.5000000e+01 9.5152748e-01 6.9016814e-03 3.6035070e-01\n",
      " 9.8137832e-01 1.0001261e+00]\n",
      "[0.0000000e+00 1.5000000e+01 9.6201873e-01 1.0214329e-02 3.6676759e-01\n",
      " 9.8252100e-01 9.9907678e-01]\n",
      "[0.0000000e+00 1.5000000e+01 9.5977587e-01 1.0402560e-02 3.6988550e-01\n",
      " 9.8101294e-01 9.9929267e-01]\n",
      "[0.0000000e+00 1.5000000e+01 9.5977587e-01 1.0402560e-02 3.6988550e-01\n",
      " 9.8101294e-01 9.9929267e-01]\n",
      "[0.0000000e+00 1.5000000e+01 9.3668520e-01 1.1081517e-02 3.4767437e-01\n",
      " 9.9140269e-01 9.9443448e-01]\n",
      "[0.0000000e+00 1.5000000e+01 9.7244501e-01 1.3064355e-02 3.5101593e-01\n",
      " 9.8899198e-01 9.9528122e-01]\n",
      "[0.0000000e+00 1.5000000e+01 9.7244501e-01 1.3064355e-02 3.5101593e-01\n",
      " 9.8899198e-01 9.9528122e-01]\n",
      "[0.00000000e+00 1.50000000e+01 9.73866880e-01 1.26059055e-02\n",
      " 3.43757391e-01 9.88484502e-01 9.95359659e-01]\n",
      "[0.0000000e+00 1.5000000e+01 9.6015519e-01 9.5144808e-03 3.1696063e-01\n",
      " 9.9147677e-01 9.9423474e-01]\n",
      "[0.0000000e+00 1.5000000e+01 9.6015519e-01 9.5144808e-03 3.1696063e-01\n",
      " 9.9147677e-01 9.9423474e-01]\n",
      "[0.0000000e+00 1.5000000e+01 8.7694180e-01 1.4913142e-02 3.3536720e-01\n",
      " 9.8649842e-01 9.9326003e-01]\n",
      "[0.0000000e+00 1.5000000e+01 8.5038304e-01 1.3563246e-02 3.2924888e-01\n",
      " 9.8742580e-01 9.9365044e-01]\n",
      "[0.0000000e+00 1.5000000e+01 8.5038304e-01 1.3563246e-02 3.2924888e-01\n",
      " 9.8742580e-01 9.9365044e-01]\n",
      "[ 0.         15.          0.8592414   0.01500174  0.35114083  0.9802247\n",
      "  1.0016156 ]\n",
      "[0.0000000e+00 1.5000000e+01 7.4172348e-01 3.8203895e-03 3.0840436e-01\n",
      " 9.9657845e-01 9.9150670e-01]\n",
      "[0.0000000e+00 1.5000000e+01 8.0023575e-01 6.9782138e-04 2.8885898e-01\n",
      " 9.9925959e-01 9.9430907e-01]\n",
      "[0.0000000e+00 1.5000000e+01 8.0023575e-01 6.9782138e-04 2.8885898e-01\n",
      " 9.9925959e-01 9.9430907e-01]\n",
      "[0.0000000e+00 1.5000000e+01 6.7684770e-01 9.4962120e-03 3.1032401e-01\n",
      " 9.9051249e-01 9.9103945e-01]\n"
     ]
    }
   ],
   "source": [
    "capp = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    _, image = capp.read()  # to read the cam data\n",
    "    height, width = image.shape[0], image.shape[1]\n",
    "    blob  = cv2.dnn.blobFromImage(cv2.resize(image, (300, 300)), 0.007, (300,300), 130)\n",
    "    #put the image into the neural network\n",
    "    net.setInput(blob)\n",
    "    detected_objects = net.forward()\n",
    "    print(detected_objects[0][0][0]) #result : values of the first object detected \n",
    "    # Initialize a dictionary to count each class of object\n",
    "    object_counts = {class_name: 0 for class_name in CLASSES[1:]}  # Exclude 'background'\n",
    "\n",
    "    for i in range(detected_objects.shape[2]):\n",
    "        confidence = detected_objects[0][0][i][2] #to get the confidence\n",
    "        if confidence > min_confidence: #to test if the confidence > min then we draw a rectangle on the object\n",
    "            class_id = int(detected_objects[0, 0, i, 1])\n",
    "            class_name = CLASSES[class_id]\n",
    "            if class_name in object_counts:\n",
    "                object_counts[class_name] += 1\n",
    "        #to get the exact coordinates of the whole object\n",
    "            upper_left_x = int(detected_objects[0, 0, i, 3]* width)\n",
    "            upper_left_y = int(detected_objects[0, 0, i, 4]* height)\n",
    "            lower_right_x = int(detected_objects[0, 0, i, 5]* width)\n",
    "            lower_right_y = int(detected_objects[0, 0, i, 6]* height) \n",
    "        #get the name of the object and the value of the confidence\n",
    "            prediction_txt = f\"{CLASSES[class_id]}: {confidence:.2f}%\"  \n",
    "        #draw the rectangle\n",
    "            cv2.rectangle(image, (upper_left_x, upper_left_y), (lower_right_x, lower_right_y), colors[class_id], 3)\n",
    "        #the position of the text ( if there is no space we change the position)\n",
    "            cv2.putText(image, prediction_txt, (upper_left_x, upper_left_y - 15 if upper_left_y > 30 else upper_left_y + 15), cv2.FONT_HERSHEY_SIMPLEX, 0.6, colors[class_id], 2)\n",
    "        # Display object counts on the image\n",
    "    y_position = 30\n",
    "    for class_name, count in object_counts.items():\n",
    "        cv2.putText(image, f\"{class_name}: {count}\", (10, y_position), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        y_position += 30\n",
    "    cv2.imshow(\"Detected objects\", image)\n",
    "    cv2.waitKey(5) #0 will freeze the image\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
